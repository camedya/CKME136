---
title: "Capstone Project - Perceived Mental Health"
author: "J. Albanese"
date: "April 9, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Data will be analyzed in two sets - Perceived Mental Health, Very Good or Excellent (%) and Perceived Mental Health, Fair or Poor (%). Results will be analyzed in parallel to determine historic mental health trends.

** PERCEIVED MENTAL HEALTH, VERY GOOD OR EXCELLENT **

Import Very Good or Excellent data to analyze and represent visually.

```{r}
library('ggplot2')
Good<-read.csv('C:/Users/alba67300/Documents/ZOther/School/CKME136 - Data Analytics Capstone Project/CKME DataSets/Good.csv',header=TRUE)
ggplot(data=Good,aes(x=Year,y=Total),) + geom_line(aes(colour=Name)) + labs(y = "Percent") + labs(colour="Province")
```

First, must review and eliminate possible outliers from each data set. 

```{r}
bxplt_Good<-boxplot(Total~Name,data=Good)
bxplt_Good
G<-subset(Good,select=-c(Code))
G$Total[(G$Total==64.7&G$Name == "New Brunswick")] <- quantile(G$Total[G$Name=="New Brunswick"],0.25)-1.5*IQR(G$Total[G$Name=="New Brunswick"])
G$Total[(G$Total==67.2 & G$Name == "Saskatchewan")] <- quantile(G$Total[G$Name=="Saskatchewan"],0.25)-1.5*IQR(G$Total[G$Name=="Saskatchewan"])
boxplot(Total~Name,data=G)
```

Separate into individual files by province to determine if a parametric or non-parametric analysis will be conducted. Evaluate normality of the individual datasets and determine if the variances of each dataset can be considered statistically equal to each other.

```{r}
BCG<-G[G$Name=='British Columbia',]
AG<-G[G$Name=='Alberta',]
SG<-G[G$Name=='Saskatchewan',]
MG<-G[G$Name=='Manitoba',]
OG<-G[G$Name=='Ontario',]
QG<-G[G$Name=='Quebec',]
NBG<-G[G$Name=='New Brunswick',]
NSG<-G[G$Name=='Nova Scotia',]
PEIG<-G[G$Name=='Prince Edward Island',]
NG<-G[G$Name=='Newfoundland and Labrador',]
```

Perform Shapiro-Wilk test to determine normality.
Ho = data is normally distributed
Ha = data is not normally distributed
alpha = 0.05

```{r}
shapiro.test(BCG$Total)
shapiro.test(AG$Total)
shapiro.test(SG$Total)
shapiro.test(MG$Total)
shapiro.test(OG$Total)
shapiro.test(QG$Total)
shapiro.test(NBG$Total)
shapiro.test(NSG$Total)
shapiro.test(PEIG$Total)
shapiro.test(NG$Total)
```

Based on p-values for each provincial data set as calculated using the Shapiro-Wilk test, each null hypothesis can't be rejected and all datasets are assumed to be normally distributed.

Graphically represent the data to visually confirm data is sufficiently normally distributed.

```{r, echo = FALSE}

par(mfrow=c(3,4))
plot(density(BCG$Total), main = "British Columbia")
plot(density(AG$Total), main = "Alberta")
plot(density(SG$Total), main = "Saskatchewan")
plot(density(MG$Total), main = "Manitoba")
plot(density(OG$Total), main = "Ontario")
plot(density(QG$Total), main = "Quebec")
plot(density(NBG$Total), main = "New Brunswick")
plot(density(NSG$Total), main = "Nova Scotia")
plot(density(PEIG$Total), main = "Prince Edward Island")
plot(density(NG$Total), main = "Newfoundland")

```

```{r, echo = FALSE}

par(mfrow=c(3,4))
qqnorm(BCG$Total, main = "British Columbia")
qqline(BCG$Total,col=2)
qqnorm(AG$Total, main = "Alberta")
qqline(AG$Total,col=2)
qqnorm(SG$Total, main = "Saskatchewan")
qqline(SG$Total,col=2)
qqnorm(MG$Total, main = "Manitoba")
qqline(MG$Total,col=2)
qqnorm(OG$Total, main = "Ontario")
qqline(OG$Total,col=2)
qqnorm(QG$Total, main = "Quebec")
qqline(QG$Total,col=2)
qqnorm(NBG$Total, main = "New Brunswick")
qqline(NBG$Total,col=2)
qqnorm(NSG$Total, main = "Nova Scotia")
qqline(NSG$Total,col=2)
qqnorm(PEIG$Total, main = "Prince Edward Island")
qqline(PEIG$Total,col=2)
qqnorm(NG$Total, main = "Newfoundland")
qqline(NG$Total,col=2)

```

Confirm if dataset variances can be considered equal. Calculate variances of each dataset, determine if variances create a normally distributed dataset and compare, in turn, each variance to the mean of the remaining dataset using an independent two-tailed t-distribution (as it is a small sample size).
Ho = variance is equal to mean
Ha = variance is not equal to mean
alpha = 0.05
```{r}
GoodVars<-c(var(BCG$Total),var(AG$Total),var(SG$Total),var(MG$Total),var(OG$Total),var(QG$Total),var(NBG$Total),var(NSG$Total),var(PEIG$Total),var(NG$Total))
t.test(GoodVars[-1],mu=GoodVars[1])
t.test(GoodVars[-2],mu=GoodVars[2])
t.test(GoodVars[-3],mu=GoodVars[3])
t.test(GoodVars[-4],mu=GoodVars[4])
t.test(GoodVars[-5],mu=GoodVars[5])
t.test(GoodVars[-6],mu=GoodVars[6])
t.test(GoodVars[-7],mu=GoodVars[7])
t.test(GoodVars[-8],mu=GoodVars[8])
t.test(GoodVars[-9],mu=GoodVars[9])
t.test(GoodVars[-10],mu=GoodVars[10])
```

Looking at the results of the t-tests for the variances, there are five instances were the null hypothesis can be rejected because the p-value is less than the alpha value of 0.05. These rejections indicate that the variances are not statistically equal so a non-parametric test is required to analyze the original dataset.

A Friedman test will be performed to compare the ten different populations and determine if at least two of the ten (10) distributions differ. The years are the blocks (b) and the provinces are the treatments (k).
Ho = Provincial data sets are all the same
Ha = at least two of the dataset distributions differ
alpha = 0.05

```{r}
GoodDF<-data.frame(Year=as.factor(G$Year),Province=G$Name,Perc=G$Total,Item=G$Item)

friedman.test(Perc~Province|Year, data=GoodDF)
```

Based on the results of the Friedman test, where the p-value is less than the alpha value, at least two (2) of the Provincial populations differ. In order to determine which, posthoc analysis using the Nemenyi method will be used.

```{r}
library('PMCMR')
posthoc.friedman.nemenyi.test(Perc~Province|Year,data=GoodDF)
```



** PERCEIVED MENTAL HEALTH, FAIR OR POOR **

Import Fair or Poor data to analyze and represent visually.

```{r}
Poor<-read.csv('C:/Users/alba67300/Documents/ZOther/School/CKME136 - Data Analytics Capstone Project/CKME DataSets/Poor.csv',header=TRUE)
ggplot(data=Poor,aes(x=Year,y=Total),) + geom_line(aes(colour=Name)) + labs(y = "Percent") + labs(colour="Province")
```

First, must review and eliminate possible outliers from each data set. 

```{r}
bxplt_Poor<-boxplot(Total~Name,data=Poor)
bxplt_Poor
P<-subset(Poor,select=-c(ï..Code))
P$Total[(P$Total==7.2& P$Name == "Alberta")] <- quantile(P$Total[P$Name=="Alberta"],0.75)+1.5*IQR(P$Total[P$Name=="Alberta"])
P$Total[(P$Total==8.5& P$Name == "British Columbia")] <- quantile(P$Total[P$Name=="British Columbia"],0.75)+1.5*IQR(P$Total[P$Name=="British Columbia"])
P$Total[(P$Total==8.7& P$Name == "New Brunswick")] <- quantile(P$Total[P$Name=="New Brunswick"],0.75)+1.5*IQR(P$Total[P$Name=="New Brunswick"])
P$Total[((P$Total==7.0|P$Total==7.1)&P$Name == "Prince Edward Island")] <- quantile(P$Total[P$Name=="Prince Edward Island"],0.75)+1.5*IQR(P$Total[P$Name=="Prince Edward Island"])
boxplot(Total~Name,data=P)
```

Seperate into individual files by province to determine if a parametric or non-parametric analysis will be conducted. Evaluate normality of the individual datasets and determine if the variances of each dataset can be considered statistically equal to each other.

```{r}
BCP<-P[P$Name=='British Columbia',]
AP<-P[P$Name=='Alberta',]
SP<-P[P$Name=='Saskatchewan',]
MP<-P[P$Name=='Manitoba',]
OP<-P[P$Name=='Ontario',]
QP<-P[P$Name=='Quebec',]
NBP<-P[P$Name=='New Brunswick',]
NSP<-P[P$Name=='Nova Scotia',]
PEIP<-P[P$Name=='Prince Edward Island',]
NP<-P[P$Name=='Newfoundland and Labrador',]
```

Perform Shapiro-Wilk test to determine normality.
Ho = data is normally distributed
Ha = data is not normally distributed
alpha = 0.05

```{r}
shapiro.test(BCP$Total)
shapiro.test(AP$Total)
shapiro.test(SP$Total)
shapiro.test(MP$Total)
shapiro.test(OP$Total)
shapiro.test(QP$Total)
shapiro.test(NBP$Total)
shapiro.test(NSP$Total)
shapiro.test(PEIP$Total)
shapiro.test(NP$Total)
```

Based on p-values for each provincial data set as calculated using the Shapiro-Wilk test, not all data sets are normally distributed so non-parametric statistical comparisons will be used.

Graphically represent the data to visually confirm not all data is sufficiently normally distributed.

```{r, echo = FALSE}

par(mfrow=c(3,4))
plot(density(BCP$Total), main = "British Columbia")
plot(density(AP$Total), main = "Alberta")
plot(density(SP$Total), main = "Saskatchewan")
plot(density(MP$Total), main = "Manitoba")
plot(density(OP$Total), main = "Ontario")
plot(density(QP$Total), main = "Quebec")
plot(density(NBP$Total), main = "New Brunswick")
plot(density(NSP$Total), main = "Nova Scotia")
plot(density(PEIP$Total), main = "Prince Edward Island")
plot(density(NP$Total), main = "Newfoundland")

```

```{r, echo = FALSE}

par(mfrow=c(3,4))
qqnorm(BCP$Total, main = "British Columbia")
qqline(BCP$Total,col=2)
qqnorm(AP$Total, main = "Alberta")
qqline(AP$Total,col=2)
qqnorm(SP$Total, main = "Saskatchewan")
qqline(SP$Total,col=2)
qqnorm(MP$Total, main = "Manitoba")
qqline(MP$Total,col=2)
qqnorm(OP$Total, main = "Ontario")
qqline(OP$Total,col=2)
qqnorm(QP$Total, main = "Quebec")
qqline(QP$Total,col=2)
qqnorm(NBP$Total, main = "New Brunswick")
qqline(NBP$Total,col=2)
qqnorm(NSP$Total, main = "Nova Scotia")
qqline(NSP$Total,col=2)
qqnorm(PEIP$Total, main = "Prince Edward Island")
qqline(PEIP$Total,col=2)
qqnorm(NP$Total, main = "Newfoundland")
qqline(NP$Total,col=2)

```

A Friedman test will be performed to compare the ten different populations and determine if at least two of the ten distributions differ. The years are the blocks (b) and the provinces are the treatments (k).
Ho = Provincial data sets are all the same
Ha = at least two of the dataset distributions differ
alpha = 0.05

```{r}
PoorDF<-data.frame(Year=as.factor(P$Year),Province=P$Name,Perc=P$Total,Item=P$Item)

friedman.test(Perc~Province|Year, data=PoorDF)
```

Based on the results of the Friedman test, with a p-value less than the alpha threshold, at least two (2) of the Provincial populations differ. In order to determine which, posthoc analysis using the Nemenyi method will be used.

```{r}
posthoc.friedman.nemenyi.test(Perc~Province|Year,data=PoorDF)
```



** YEARLY TRENDS **

Lastly, the data sets will be analyzed to determine if there has been a significant increase or decrease in perceived mental health over the last 13 years.

```{r}
G2003<-G[G$Year==2003,]
G2016<-G[G$Year==2016,]
P2003<-P[P$Year==2003,]
P2016<-P[P$Year==2016,]
shapiro.test(G2003$Total)
shapiro.test(G2016$Total)
shapiro.test(P2003$Total)
shapiro.test(P2016$Total)
par(mfrow=c(2,4))
plot(density(G2003$Total), main = "Good 2003")
plot(density(G2016$Total), main = "Good 2016")
plot(density(P2003$Total), main = "Poor 2003")
plot(density(P2016$Total), main = "Poor 2016")
qqnorm(G2003$Total, main = "Good 2003")
qqline(G2003$Total,col=2)
qqnorm(G2016$Total, main = "Good 2016")
qqline(G2016$Total,col=2)
qqnorm(P2003$Total, main = "Poor 2003")
qqline(P2003$Total,col=2)
qqnorm(P2016$Total, main = "Poor 2016")
qqline(P2016$Total,col=2)
```

Both the Perceived Mental Health Good and Poor show that they are normally distributed so variance calculations will be performed to determine if parametric or non-parametric tests should be performed.
```{r}
var.test(G2003$Total,G2016$Total)
var.test(P2003$Total,P2016$Total)
```

As the variances are equal, parametric comparisons will be used on the Good and Poor data sets.
Ho = Yearly data sets are the same
Ha = Datasets differ
alpha = 0.05

```{r}
t.test(G2003$Total,G2016$Total,paired=TRUE)
t.test(P2003$Total,P2016$Total,paired=TRUE)
```

As both p-values are below the threshold of 0.05, the null hypothesis can be rejected and it is determined that there is statistical significance between the values in 2003 and the values in 2016. 



** ADDITIONAL MODELLING - NOT PART OF PAPER **

Modelling these trends in order to predict the percentage of provincial populations that will classify themselves into one of the two categories will be beneficial.

First we will combine the data in order to create a single model for the entire data set. From the combined data set a training and test data set will be created in order to create and evaluate the models. An 80/20 split of the data will be used.

```{r}
All<-rbind(G,P)
All_Index<-sample(1:nrow(All),0.8*nrow(All))
All_Train<-All[All_Index,]
All_Test<-All[-All_Index,]
```

In order to determine which of the parameters should be included in the multiple linear regression model, a stepwise analysis of each model type will be conducted to determine prameter significance.
```{r}
library(MASS)
full<-lm(Total~Name+Item+Year,data=All)
null<-lm(Total~1,data=All)
stepF<-stepAIC(null,scope=list(lower=null,upper=full),direction="forward",trace=TRUE)
summary(stepF)
```
The model will be expected to evaluated at a 90% confidence interval. With this threshold in place, all parameters (Year, Name, Item) are deemed to be significant as per the stepwise AIC evaluation. The AIC value for the mlr inclusive of all parameters is smallest and therefore the best fit for the data.

Interesting to note is that Quebec is the only province with a positive mental wellbeing trend as captured by it's positive coefficient. All other provinces have negative coefficients which indicate that they have negative mental wellbeing trends year to year.

Using this data, the model is trained and tested. 
```{r}
model_mlr<-lm(Total~Name+Item+Year,data=All_Train)
predict<-predict(model_mlr,interval="prediction",newdata=All_Test)
errors<-predict[,"fit"]-All_Test$Total
hist(errors)
```

The distribution of errors has a roughly normally distributed shape indicating a good fit. The calculated values using the model and the actual values from the test set will be comapred to determine if they are equal.

Ho = mean of values from model is equal to the mean of values from test set.
Ha = two sets of values aren't equal
alpha = 0.05

```{r}
par(mfrow = c(2,2))
plot(predict[,"fit"], main = "Predicted Values", ylab = "Percentage (%)")
plot(All_Test$Total, main = "Actual Values", ylab = "Percentage (%)")
plot(density(predict[,"fit"]),main = "Predicted Values")
plot(density(All_Test$Total), main = "Actual Values")
```

Clearly data is not parametric, so a Wilcoxon Rank Sum test will be used to validate null hypothesis. The data is paired as the values have come from the same parameters.

```{r}
wilcox.test(predict[,"fit"],All_Test$Total,paired=TRUE)
```

As the p-value is greated than 0 .05, the null hypothesis holds and the actual values for the data are concluded to be statistically equal to the predicted values from the model. Therefore, the model is a good fit and can be used to predict future perceived provincial mental wellbeing.

```{r}
Predict2017<-read.csv('C:/Users/alba67300/Documents/ZOther/School/CKME136 - Data Analytics Capstone Project/CKME DataSets/2017Predict.csv',header=TRUE)
Cal2017<-predict(model_mlr,interval="prediction",newdata=Predict2017)
Bind2017<-cbind(Predict2017,Cal2017)
Bind2017
```



